{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Assessment2_MMM_Mediation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {"id": "cell-setup"},
      "source": [
        "#@title Install / imports / config\n",
        "!pip -q install -U \"numpy>=2.0.0,<2.3\" scikit-learn==1.5.2 matplotlib==3.9.2 pandas==2.2.2\n\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt, json, math, warnings, random, os\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.linear_model import ElasticNetCV, LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "os.environ[\"PYTHONHASHSEED\"]=\"0\"; random.seed(42); np.random.seed(42)\n",
        "plt.rcParams[\"figure.figsize\"] = (10,4); plt.rcParams[\"axes.grid\"] = True\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {"id": "cell-upload"},
      "source": [
        "#@title Upload your CSV (pick \"Assessment 2 - MMM Weekly.csv\")\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "csv_path = list(uploaded.keys())[0]\n",
        "df = pd.read_csv(csv_path)\n",
        "df.head(3)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {"id": "cell-helpers"},
      "source": [
        "class DateFeatures(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, date_col=\"week\"): self.date_col = date_col\n",
        "    def fit(self, X, y=None): return self\n",
        "    def transform(self, X):\n",
        "        xx = X.copy()\n",
        "        xx[self.date_col] = pd.to_datetime(xx[self.date_col], errors=\"coerce\")\n",
        "        xx[\"year\"] = xx[self.date_col].dt.year\n",
        "        xx[\"weekofyear\"] = xx[self.date_col].dt.isocalendar().week.astype(int)\n",
        "        xx[\"month\"] = xx[self.date_col].dt.month\n",
        "        xx[\"t\"] = np.arange(len(xx))\n",
        "        return xx[[\"year\",\"weekofyear\",\"month\",\"t\"]]\n\n",
        "def adstock_geometric(x, lam=0.6):\n",
        "    x = np.nan_to_num(np.asarray(x, float), nan=0.0)\n",
        "    out = np.zeros_like(x, dtype=float)\n",
        "    for i, v in enumerate(x): out[i] = v + (lam * (out[i-1] if i>0 else 0.0))\n",
        "    return out\n\n",
        "def mape(y_true, y_pred, eps=1.0):\n",
        "    yt = np.maximum(np.asarray(y_true, float), eps)\n",
        "    yp = np.asarray(y_pred, float)\n",
        "    return np.mean(np.abs((yt - yp) / yt)) * 100.0\n\n",
        "def print_metrics(name, y_true, y_pred):\n",
        "    res = {\"R2\": r2_score(y_true, y_pred),\n",
        "           \"RMSE\": mean_squared_error(y_true, y_pred, squared=False),\n",
        "           \"MAPE_%\": mape(y_true, y_pred)}\n",
        "    print(name, json.dumps(res, indent=2)); return res\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {"id": "cell-prepcols"},
      "source": [
        "df = df.copy()\n",
        "df[\"week\"] = pd.to_datetime(df[\"week\"], errors=\"coerce\")\n",
        "df = df.sort_values(\"week\").reset_index(drop=True)\n\n",
        "target_col, mediator_col = \"revenue\", \"google_spend\"\n",
        "social_cols = [\"facebook_spend\",\"tiktok_spend\",\"instagram_spend\",\"snapchat_spend\"]\n",
        "controls    = [\"social_followers\",\"emails_send\",\"sms_send\"]\n",
        "price_col, promo_col = \"average_price\", \"promotions\"\n\n",
        "X_dates = DateFeatures(\"week\").transform(df)\n",
        "n = len(df); test_size = max(1, int(math.ceil(0.20*n))); split_ix = n - test_size\n",
        "print(\"Rows:\", n, \"Holdout:\", test_size)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {"id": "cell-stage1"},
      "source": [
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "lam_grid = [0.3, 0.5, 0.6, 0.7, 0.9]\n",
        "best = (-1e9, None, None)\n\n",
        "for lam in lam_grid:\n",
        "    X_ad = pd.DataFrame({f\"{c}_adstock_log1p\": np.log1p(adstock_geometric(df[c].fillna(0), lam)) for c in social_cols})\n",
        "    X1 = pd.concat([X_ad, X_dates, df[controls].fillna(0)], axis=1)\n",
        "    y1 = np.log1p(df[mediator_col].fillna(0))\n",
        "    pipe = Pipeline([(\"scaler\", StandardScaler()),\n",
        "                     (\"enet\", ElasticNetCV(l1_ratio=[0.1,0.5,0.9], alphas=np.logspace(-4,1,40),\n",
        "                                           cv=tscv, max_iter=20000, random_state=42))])\n",
        "    oof = np.zeros_like(y1, dtype=float)\n",
        "    for tr, te in tscv.split(X1):\n",
        "        pipe.fit(X1.iloc[tr], y1.iloc[tr]); oof[te] = pipe.predict(X1.iloc[te])\n",
        "    r2o = r2_score(y1, oof)\n",
        "    if r2o > best[0]: best = (r2o, lam, pipe.fit(X1, y1))\n\n",
        "lam_star, model1 = best[1], best[2]\n",
        "print(\"Best mediator λ:\", lam_star, \" | OOF R2:\", best[0])\n\n",
        "df[\"g_log1p_hat\"] = model1.predict(pd.concat([\n",
        "    pd.DataFrame({f\"{c}_adstock_log1p\": np.log1p(adstock_geometric(df[c].fillna(0), lam_star)) for c in social_cols}),\n",
        "    X_dates, df[controls].fillna(0)\n",
        "], axis=1))\n",
        "df[\"g_hat\"] = np.expm1(df[\"g_log1p_hat\"])\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {"id": "cell-stage2"},
      "source": [
        "def make_stage2_features(dd):\n",
        "    X = pd.DataFrame({\"log1p_avg_price\": np.log1p(dd[price_col].fillna(0)),\n",
        "                      \"log1p_g_hat\":     np.log1p(dd[\"g_hat\"].fillna(0))})\n",
        "    return pd.concat([X, dd[[promo_col]+controls].fillna(0), X_dates], axis=1)\n\n",
        "X2 = make_stage2_features(df)\n",
        "y2 = np.log1p(df[target_col].clip(lower=1e-6))\n",
        "X2_tr, X2_te = X2.iloc[:split_ix], X2.iloc[split_ix:]\n",
        "y2_tr, y2_te = y2.iloc[:split_ix], y2.iloc[split_ix:]\n\n",
        "enet = Pipeline([(\"scaler\", StandardScaler()),\n",
        "                 (\"enet\", ElasticNetCV(l1_ratio=[0.1,0.5,0.9], alphas=np.logspace(-4,1,40),\n",
        "                                       cv=TimeSeriesSplit(n_splits=5), max_iter=20000, random_state=42))])\n",
        "enet.fit(X2_tr, y2_tr)\n",
        "pred_tr = np.expm1(enet.predict(X2_tr)); pred_te = np.expm1(enet.predict(X2_te))\n",
        "act_tr  = np.expm1(y2_tr);                act_te  = np.expm1(y2_te)\n\n",
        "print_metrics(\"ElasticNet — Train\", act_tr, pred_tr)\n",
        "print_metrics(\"ElasticNet — Test\",  act_te, pred_te)\n\n",
        "plt.plot(df[\"week\"].iloc[:split_ix], act_tr, label=\"Actual (train)\")\n",
        "plt.plot(df[\"week\"].iloc[:split_ix], pred_tr, label=\"Pred (train)\"); plt.legend(); plt.title(\"Train\"); plt.show()\n",
        "plt.plot(df[\"week\"].iloc[split_ix:], act_te, label=\"Actual (test)\")\n",
        "plt.plot(df[\"week\"].iloc[split_ix:], pred_te, label=\"Pred (test)\"); plt.legend(); plt.title(\"Test\"); plt.show()\n\n",
        "coef = pd.Series(enet.named_steps[\"enet\"].coef_, index=X2_tr.columns).sort_values(ascending=False)\n",
        "coef.to_frame(\"coef\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {"id": "cell-optional-boost"},
      "source": [
        "Xad = pd.DataFrame({f\"ad_{c}\": adstock_geometric(df[c].fillna(0), lam_star) for c in social_cols})\n",
        "resid = {}\n",
        "gX = df[\"g_log1p_hat\"].values.reshape(-1,1)\n",
        "for col in Xad.columns:\n",
        "    lr = LinearRegression().fit(gX, Xad[col].values)\n",
        "    resid[col+\"_resid\"] = Xad[col].values - lr.predict(gX)\n",
        "X_resid = pd.DataFrame(resid)\n\n",
        "X2b = pd.concat([make_stage2_features(df), X_resid], axis=1)\n",
        "X2b_tr, X2b_te = X2b.iloc[:split_ix], X2b.iloc[split_ix:]\n\n",
        "hgb = HistGradientBoostingRegressor(max_depth=6, learning_rate=0.05, max_iter=1000, min_samples_leaf=8, random_state=42)\n",
        "hgb.fit(X2b_tr, y2_tr)\n",
        "pred_tr_b = np.expm1(hgb.predict(X2b_tr)); pred_te_b = np.expm1(hgb.predict(X2b_te))\n",
        "print_metrics(\"Boosting — Train\", act_tr, pred_tr_b)\n",
        "print_metrics(\"Boosting — Test\",  act_te, pred_te_b)\n\n",
        "plt.plot(df[\"week\"].iloc[split_ix:], act_te, label=\"Actual (test)\")\n",
        "plt.plot(df[\"week\"].iloc[split_ix:], pred_te_b, label=\"Pred (test)\"); plt.legend(); plt.title(\"Test — Boosting\"); plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {"id": "cell-sensitivity"},
      "source": [
        "last = df.iloc[[-1]].copy()\n",
        "grid = np.linspace(0.9*last[price_col].item(), 1.1*last[price_col].item(), 9)\n",
        "rows = []\n",
        "for promo in [0,1]:\n",
        "    for p in grid:\n",
        "        tmp = last.copy(); tmp[price_col] = p\n",
        "        Xtmp = make_stage2_features(tmp.assign(g_hat=last[\"g_hat\"].values))\n",
        "        rows.append({\"promotion\": promo, \"avg_price\": p, \"pred_revenue\": float(np.expm1(enet.predict(Xtmp))[0])})\n",
        "sens = pd.DataFrame(rows); sens\n",
        "for promo in [0,1]:\n",
        "    sub = sens[sens[\"promotion\"]==promo]\n",
        "    plt.plot(sub[\"avg_price\"], sub[\"pred_revenue\"], label=f\"Promo={promo}\")\n",
        "plt.title(\"Sensitivity to Average Price (±10%)\"); plt.xlabel(\"Average Price\"); plt.ylabel(\"Predicted Revenue\"); plt.legend(); plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ]
}
